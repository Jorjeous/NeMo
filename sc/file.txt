docker run -it --rm --gpus='all' --ipc=host --shm-size=8g --ulimit memlock=-1 --name QN20-LSP--local-bs8xg1xn1--16 -v /home/gzelenfroind/Quartznet_info/data/LibriSpeech:/data/LibriSpeech/LibriSpeech:ro -v /home/gzelenfroind/QN20_TEST/:/ws gitlab-master.nvidia.com/vbataev/nemo_containers:v1.11.0_22.08 bash -c "echo "*******STARTING********" && echo "---------------" && nvidia-smi && export WANDB_API_KEY=fae11c5bf2e02ec19bbe92849e7637a568959380 && mkdir -p /ws/exp/QN20-LSP--local-bs8xg1xn1--16 && cd /ws/exp/QN20-LSP--local-bs8xg1xn1--16 && echo "POINT_1" && pwd && ls && echo "QN20-LSP--local-bs8xg1xn1--16" && echo QN20-LSP--local-bs8xg1xn1--16 && echo "CN" && echo quartznet2_str4_cos_ctc_no_joint.yaml && echo "CP" && echo /ws/NeMo/examples/asr/conf/quartznet/ && echo "TM" && echo /data/LibriSpeech_tarred/tarred_audio_manifest.json && HYDRA_FULL_ERROR=1 python3 /ws/NeMo/examples/asr/asr_ctc/speech_to_text_ctc_bpe.py --config-name=quartznet2_str4_cos_ctc_no_joint.yaml --config-path=/ws/NeMo/examples/asr/conf/quartznet/ ++model.train_ds.manifest_filepath=/data/LibriSpeech_tarred/tarred_audio_manifest.json ++model.validation_ds.manifest_filepath=[/ws/code/exprunner/manifests/librispeech/dev_other.json,/ws/code/exprunner/manifests/librispeech/dev_clean.json,/ws/code/exprunner/manifests/librispeech/test_clean.json,/ws/code/exprunner/manifests/librispeech/test_other.json] ++model.train_ds.num_workers=8 ++model.validation_ds.num_workers=8 ++model.train_ds.batch_size=8 ++model.optim.sched.min_lr=1e-6 ++model.optim.sched.warmup_steps=10000 ++trainer.num_nodes=1 ++trainer.accumulate_grad_batches=1 ++trainer.devices=-1 ++trainer.log_every_n_steps=100 ++exp_manager.create_wandb_logger=True ++exp_manager.wandb_logger_kwargs.name="EXP1" ++exp_manager.wandb_logger_kwargs.project="Proj 1" ++exp_manager.wandb_logger_kwargs.resume=auto ++exp_manager.wandb_logger_kwargs.id="1""
